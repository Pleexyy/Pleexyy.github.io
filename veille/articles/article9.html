<!DOCTYPE html>
<html lang="fr">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="theme-color" content="#000000" />
    <title>Le piratage des voitures autonomes</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
        integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link href="../theme.css" rel="stylesheet">
    <script src="../main.js"></script>
</head>

<body>
    <!-- Barre de navigation (fixe) -->
    <nav class="navbar navbar-light bg-transparent pb-4" id="nav">
        <a class="navbar-brand" id="main-menu" href="../index.html"><b>Accueil</b></a>
        <i class="fa fa-adjust" id="switch"></i>
    </nav>

    <div class="container">
        <h2><b>Le piratage des voitures autonomes</b></h2>
        <h6><b>1 mars 2020</b></h6>
        <h6>Par Olivier Hertel</h6>
        <h4>Des images fantômes pour pirater les voitures autonomes</h4>

        <img src="../images/images-fantomes.jpg" width="80%" height="80%" class="img">

        <p>De simples images projetées sur la route peuvent tromper les systèmes d’aides
            à la conduite des voitures semi ou totalement autonomes les plus sophistiqués.
            Un piratage à la portée de tous jugé extrêmement dangereux par les chercheurs qui viennent d'en faire la
            démonstration.
        </p>

        <p>
            Pour pirater une voiture autonome, pas besoin d'être un petit génie du clavier ! Un simple vidéoprojecteur
            suffit.
            C'est ce que vient de montrer l'équipe de Ben Nassi à l'Université Ben Gourion du Néguev en Israël en menant
            une série “d'attaques fantômes”
            contre deux systèmes d'aides à la conduite réputés les plus avancés : l'autopilote de la Tesla Model X et le
            630 PRO de Mobileye (Intel),
            un système anticollision qui peut être ajouté à n'importe quelle voiture.
            Ces attaques sont dites “fantômes” car elles consistent à projeter (depuis un drone) de simples images,
            perçues par les véhicules comme des objets bien réels.</p>

        <h4><b>La voiture réagit à un marquage imaginaire au sol</b></h4>
        <p>
            Les chercheurs ont par exemple projeté sur la route l'image d'une silhouette reconnue comme une vraie
            personne par la Tesla.
            La voiture, alors sous le contrôle du régulateur de vitesse, a brutalement freiné. Même réaction avec une
            voiture fantôme. Plus inquiétant : dans une autre expérience, de fausses lignes de voie formant un virage
            étaient projetées sur la chaussée. Cette fois, l'autopilote de la Tesla a tourné le volant pour suivre ce
            marquage imaginaire et ainsi envoyer la voiture dans le sens de circulation opposé. Heureusement, le test,
            filmé (voir la vidéo ci-dessous), a été mené sur un parking désert. Mais la séquence donne une bonne idée
            des conséquences que pourrait avoir une telle décision prise par les algorithmes si l'humain ne reprenait
            pas le contrôle.</p>

        <p>Dans une troisième expérience, les chercheurs se sont amusés à projeter un panneau de limitation de vitesse
            dans le feuillage d'un arbre bordant la route. Malgré l'image d'assez mauvaise qualité, le système Mobileye
            est suffisamment performant… pour se faire berner. Il identifie bien le panneau et le considère comme un
            vrai.

            Pour Ben Nassi, ces attaques fantômes sont particulièrement dangereuses et ce pour plusieurs raisons. Grâce
            au projecteur embarqué sur un drone, elles peuvent être menées à distance et donc n'exigent pas de se rendre
            physiquement sur le lieu. Elles ne requièrent aucune expertise particulière, ne laissent aucun indice, ne
            demande pas de préparation ni de moyens importants (quelques centaines d'euros pour le drone et le
            projecteur). En d'autres termes, elles sont à la portée de quiconque voudrait nuire en provoquant des
            collisions, en détournant la circulation, en créant des embouteillages etc…</p>

        <h4><b>Le principe de précaution appliqué aux algorithmes</b></h4>

        <p>Dans le cas de Tesla, les résultats sont d'autant plus surprenants que le système utilise plusieurs capteurs
            pour surveiller la route et notamment un radar capable de détecter la présence d'un objet réel. Alors
            pourquoi la voiture s'est fiée à la reconnaissance d'image pour détecter un piéton et non à son radar qui ne
            détectait rien ? Selon Ben Nassi, cela est probablement dû à une sorte de principe de précaution appliqué
            aux algorithmes. Même si l'objet n'est pas détecté par tous les capteurs, la voiture considère qu'il est
            bien présent. Mais cette stratégie prudente montre là ses faiblesses car elle conduit à des décisions
            automatiques dangereuses.</p>

        <p>Selon le chercheur israélien, il est toutefois possible d'entraîner ces systèmes à reconnaître très
            précisément ces images fantômes en analysant finement les informations fournies uniquement par les caméras :
            est-ce que la présence de l'objet à tel endroit est possible, est-ce qu'il réfléchit normalement la lumière
            (trop brillant alors qu'il est dans l'ombre…), sa surface est-elle normale (la surface du panneau dans
            l'arbre n'est pas uniforme comparée celle d'un vrai panneau), etc…</p>

        <p>Ces travaux ont de quoi saper l'optimisme des entreprises engagées dans le développement de la voiture
            autonome tant ils démontrent à quel point il est simple de leurrer les technologies les plus complexes du
            moment. Les chercheurs ont d'ailleurs alerté Tesla et Mobileye.</p>

        <!-- Sources -->
        <p class="text-right"><a
                href="https://flipboard.com/@flipboardfrance/tech-la-une-p28rdmclz/des-images-fant-mes-pour-pirater-les-voitures-autonomes/a-QNBkOrdBST2ooqyuenZyog%3Aa%3A26213650-9e72fdc702%2Fsciencesetavenir.fr"
                class="text-dark" target="_blank">Source 1 : flipboard</a></p>
        <p class="text-right"><a
                href="https://www.sciencesetavenir.fr/high-tech/transports/des-images-fantomes-trompent-les-voitures-autonomes_141384"
                class="text-dark" target="_blank">Source 2 : sciences et avenir</a></p>
    </div>

    <footer class="footer mt-auto py-3">
        <div class="container-fluid text-center">
            <span class="text-muted">&copy; 2019-2020 - Thibaud Bonneville</span>
        </div>
    </footer>

</body>


</html>